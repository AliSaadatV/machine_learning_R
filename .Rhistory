step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
# Stratified sampling with the rsample package
set.seed(123)
ames <- AmesHousing::make_ames()
split <- initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal()) %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
# Specify resampling plan
cv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
# Construct grid of hyperparameter values
hyper_grid <- expand.grid(k = seq(2, 25, by = 1))
# Tune a knn model using grid search
knn_fit2 <- train(
blueprint,
data = ames_train,
method = "knn",
trControl = cv,
tuneGrid = hyper_grid,
metric = "RMSE"
)
ames <- AmesHousing::make_ames()
split <- rsample::initial_split(ames, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
ames_test <- rsample::testing(split)
set.seed(123)
cv_model2 <- train(
Sale_Price ~ Gr_Liv_Area + Year_Built,
data = ames_train,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
# Modeling packages
library(caret)    # for cross-validation, etc.
cv_model2 <- train(
Sale_Price ~ Gr_Liv_Area + Year_Built,
data = ames_train,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
cv_model2
resamples(cv_model2)
resamples(list(cv_model2))
summary(cv_model2)
set.seed(123)
cv_model3 <- train(
Sale_Price ~ .,
data = ames_train,
method = "lm",
trControl = trainControl(method = "cv", number = 5)
)
summary(cv_model3)
str(ames_train)
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal()) %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
# Helper packages
library(dplyr)    # for data manipulation
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal()) %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
library(recipes)
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal()) %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
cv <- trainControl(method = "cv", number = 5)
lm_model3 <- train(blueprint,
data = ames_train,
method = "lm",
trControl = cv)
cv_model2$finalModel
cv_model3$finalModel
df1 <- broom::augment(cv_model2$finalModel, data = ames_train)
View(df1)
?train
churn <- modeldata::attrition
# Helper packages
library(dplyr)     # for data wrangling
library(ggplot2)   # for awesome plotting
library(rsample)   # for data splitting
# Modeling packages
library(caret)     # for logistic regression modeling
# Model interpretability packages
library(vip)       # variable importance
glimpse(churn)
# Create training (70%) and test (30%) sets for the
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(churn, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
View(churn_train)
churn <- modeldata::attrition
# Create training (70%) and test (30%) sets for the
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(churn, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
View(churn_test)
?modeldata::attrition
churn$OverTime
View(churn)
### logistic regression
set.seed(123)
cv_model <- train(
Attrition ~ .,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
# predict class
pred_class <- predict(cv_model, churn_train)
pred_class
# create confusion matrix
confusionMatrix(
data = relevel(pred_class, ref = "Yes"),
reference = relevel(churn_train$Attrition, ref = "Yes")
)
table(churn_train$Attrition) %>% prop.table()
### logistic regression
set.seed(123)
cv_model1 <- train(
Attrition ~ MonthlyIncome,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
set.seed(123)
cv_model2 <- train(
Attrition ~ MonthlyIncome + OverTime,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
set.seed(123)
cv_model3 <- train(
Attrition ~ .,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
# extract out of sample performance measures
summary(
resamples(
list(
model1 = cv_model1,
model2 = cv_model2,
model3 = cv_model3
)
)
)$statistics$Accuracy
### Confusion matrix
# predict class
pred_class <- predict(cv_model3, churn_train)
# create confusion matrix
confusionMatrix(
data = relevel(pred_class, ref = "Yes"),
reference = relevel(churn_train$Attrition, ref = "Yes")
)
pred_class
predict(cv_model1, churn_train, type = "prob")
### ROC analysis
library(ROCR)
# Compute predicted probabilities
m1_prob <- predict(cv_model1, churn_train, type = "prob")$Yes
m2_prob <- predict(cv_model2, churn_train, type = "prob")$Yes
m3_prob <- predict(cv_model3, churn_train, type = "prob")$Yes
?predict
?caret::predict
?prediction
prediction(m1_prob, churn_train$Attrition)
prediction(m1_prob, churn_train$Attrition)->q
q
q@predictions
performance(q)
performance(q, measure = "tpr")
# Compute AUC metrics for cv_model1 and cv_model3
perf1 <- prediction(m1_prob, churn_train$Attrition) %>%
performance(measure = "tpr", x.measure = "fpr")
perf2 <- prediction(m2_prob, churn_train$Attrition) %>%
performance(measure = "tpr", x.measure = "fpr")
perf3 <- prediction(m3_prob, churn_train$Attrition) %>%
performance(measure = "tpr", x.measure = "fpr")
perf1
perf1@x.name
perf1@y.name
perf1@x.values
rm(q)
plot(perf1, col = "black", lty = 2)
plot(perf2, add = TRUE, col = "blue")
plot(perf3, add = TRUE, col = "gray")
legend(0.8, 0.2, legend = c("cv_model1", "cv_model2", "cv_model3"),
col = c("black", "blue", "gray"), lty = 2:1, cex = 0.6)
### Partial least squares (reduces number of numeric features, then performs logistic regression)
# Perform 10-fold CV on a PLS model tuning the number of PCs to
# use as predictors
set.seed(123)
cv_model_pls <- train(
Attrition ~ .,
data = churn_train,
method = "pls",
family = "binomial",
trControl = trainControl(method = "cv", number = 10),
preProcess = c("zv", "center", "scale"),
tuneLength = 16
)
# Model with lowest RMSE
cv_model_pls$bestTune
cv_model_pls
# results for model with lowest loss
cv_model_pls$results %>%
dplyr::filter(ncomp == pull(cv_model_pls$bestTune))
# Plot cross-validated RMSE
ggplot(cv_model_pls)
### Interpretation
vip(cv_model3, num_features = 20)
churn <- modeldata::attrition %>%  mutate_if(is.ordered, .funs = factor, ordered = FALSE)
# Create training (70%) and test (30%) sets for the
# rsample::attrition data.
set.seed(123)  # for reproducibility
churn_split <- initial_split(churn, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
set.seed(123)
cv_model3 <- train(
Attrition ~ .,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
### Partial least squares (reduces number of numeric features, then performs logistic regression)
# Perform 10-fold CV on a PLS model tuning the number of PCs to
# use as predictors
set.seed(123)
cv_model_pls <- train(
Attrition ~ .,
data = churn_train,
method = "pls",
family = "binomial",
trControl = trainControl(method = "cv", number = 10),
preProcess = c("zv", "center", "scale"),
tuneLength = 16
)
# Model with lowest RMSE
cv_model_pls$bestTune
# Plot cross-validated RMSE
ggplot(cv_model_pls)
### Interpretation
vip(cv_model3, num_features = 20)
### logistic regression
set.seed(123)
cv_model1 <- train(
Attrition ~ MonthlyIncome,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
set.seed(123)
cv_model2 <- train(
Attrition ~ MonthlyIncome + OverTime,
data = churn_train,
method = "glm",
family = "binomial",
trControl = trainControl(method = "cv", number = 10)
)
### Confusion matrix
# predict class
pred_class <- predict(cv_model3, churn_train)
ames <- AmesHousing::make_ames()
# Helper packages
library(recipes)  # for feature engineering
# Modeling packages
library(glmnet)   # for implementing regularized regression
library(caret)    # for automating the tuning process
# Model interpretability packages
library(vip)
set.seed(123)
split <- rsample::initial_split(anes, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
split <- rsample::initial_split(anes, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
split <- rsample::initial_split(ames, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
ames_test <- rsample::testing(split)
# Create training  feature matrices
# we use model.matrix(...)[, -1] to discard the intercept
X <- model.matrix(Sale_Price ~ ., ames_train)[, -1]
dim(x)
dim(X)
head(X)
?model.matrix
# transform y with log transformation
Y <- log(ames_train$Sale_Price)
X
### Ridge
# Apply ridge regression to ames data
ridge <- glmnet(
x = X,
y = Y,
alpha = 0
)
plot(ridge, xvar = "lambda")
ridge
ridge$lambda
names(X)
col_names(X)
colnames(X)
### Using caret package to find the best lambda (how much penalty) and alpha (alpha=0 --> Ridge, alpha=1 --> Lasso, betweeon 0 and 1 --> ENET)
# grid search across
cv_glmnet <- train(
x = X,
y = Y,
method = "glmnet",
preProc = c("zv", "center", "scale"),
trControl = trainControl(method = "cv", number = 10),
tuneLength = 10
)
# model with lowest RMSE
cv_glmnet$bestTune
# results for model with lowest RMSE
cv_glmnet$results %>%
filter(alpha == cv_glmnet$bestTune$alpha, lambda == cv_glmnet$bestTune$lambda)
# plot cross-validated RMSE
ggplot(cv_glmnet)
ames <- AmesHousing::make_ames()
set.seed(123)
split <- rsample::initial_split(ames, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
ames_test <- rsample::testing(split)
### Fit a basic MARS model
mars1 <- earth(
Sale_Price ~ .,
data = ames_train
)
# Helper packages
library(dplyr)     # for data wrangling
library(ggplot2)   # for awesome plotting
# Modeling packages
library(earth)     # for fitting MARS models
library(caret)     # for automating the tuning process
# Model interpretability packages
library(vip)       # for variable importance
library(pdp)       # for variable relationships
### Fit a basic MARS model
mars1 <- earth(
Sale_Price ~ .,
data = ames_train
)
,ars1
mars1
mars1$selected.terms
mars1$cuts
mars1
summary(mars1)
coef(mars1)
coef(mars1) %>% head(10)
ames$Functional
plot(mars1, which = 1)
seq(2, 100, length.out = 10)
### Tunning
# create a tuning grid
hyper_grid <- expand.grid(
degree = 1:3,
nprune = seq(2, 100, length.out = 10) %>% floor()
)
head(hyper_grid)
hyper_grid
hyper_grid$degree
hyper_grid$nprune
hyper_grid[1,1]
hyper_grid[1,]
hyper_grid[2,]
hyper_grid[3,]
# Helper packages
library(dplyr)      # for data wrangling
library(ggplot2)    # for awesome graphics
library(rsample)    # for creating validation splits
library(recipes)    # for feature engineering
# create training (70%) set for the rsample::attrition data.
attrit <- attrition %>% mutate_if(is.ordered, factor, ordered = FALSE)
set.seed(123)
churn_split <- initial_split(attrit, prop = .7, strata = "Attrition")
# create training (70%) set for the rsample::attrition data.
attrit <- modeldata::attrition %>% mutate_if(is.ordered, factor, ordered = FALSE)
set.seed(123)
churn_split <- initial_split(attrit, prop = .7, strata = "Attrition")
churn_train <- training(churn_split)
# Create blueprint
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes())
?bake
# Create blueprint
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
prep()
bake(blueprint)
bake(blueprint, new_data = head(churn_train))
q <- bake(blueprint, new_data = head(churn_train))
View(q)
glimpse(churn_train)
?prep
# Create blueprint
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal())
q <- bake( prep(blueprint), new_data = head(churn_train))
glimpse(q)
?all_nominal
summary(blueprint)
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction"))
q <- bake( prep(blueprint), new_data = head(churn_train))
View(q)
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement)
q <- bake( prep(blueprint), new_data = head(churn_train))
View(q)
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
q <- bake( prep(blueprint), new_data = head(churn_train))
View(q)
glimpse(churn_train)
glimpse(q)
# Create blueprint
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes())
q <- bake( prep(blueprint), new_data = head(churn_train))
glimpse(q)
# Create blueprint
blueprint <- recipe(Attrition ~ ., data = churn_train) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_nzv(all_nominal()) %>%
step_integer(contains("Satisfaction")) %>%
step_integer(WorkLifeBalance) %>%
step_integer(JobInvolvement) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
qq <- bake( prep(blueprint), new_data = head(churn_train))
glimpse(qq)
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
ames <- AmesHousing::make_ames()
set.seed(123)
split <- rsample::initial_split(ames, prop=0.7, strata="Sale_Price")
ames_train <- rsample::training(split)
ames_test <- rsample::testing(split)
table(ames_train$Overall_Qual)
install.packages("pRRophetic")
BiocManager::install("pRRophetic")
parallel::detectCores()
